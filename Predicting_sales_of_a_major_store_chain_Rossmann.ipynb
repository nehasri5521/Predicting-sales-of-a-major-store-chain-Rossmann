{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "PH-0ReGfmX4f",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehasri5521/Predicting-sales-of-a-major-store-chain-Rossmann/blob/main/Predicting_sales_of_a_major_store_chain_Rossmann.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Sales Prediction : Predicting sales of a major store chain Rossmann\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement** - \n",
        "# Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "\n",
        "# You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I'am provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. \n"
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***\n",
        "### <b>Rossmann Stores Data.csv </b> - historical data including Sales\n",
        "### <b>store.csv </b> - supplemental information about the stores\n",
        "\n",
        "\n",
        "### <b><u>Data fields</u></b>\n",
        "### Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "* #### Id - an Id that represents a (Store, Date) duple within the test set\n",
        "* #### Store - a unique Id for each store\n",
        "* #### Sales - the turnover for any given day (this is what you are predicting)\n",
        "* #### Customers - the number of customers on a given day\n",
        "* #### Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "* #### StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "* #### SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "* #### StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "* #### Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "* #### CompetitionDistance - distance in meters to the nearest competitor store\n",
        "* #### CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "* #### Promo - indicates whether a store is running a promo on that day\n",
        "* #### Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "* #### Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "* #### PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Roseman Sales Dataset** - This dataset is a live dataset of Roseman Stores. On analsysing this problem we observe that Roseman problem is a regression problem and our primarily goal is to predict the sales figures of Roseman problem. In this Notebook we work on following topics\n",
        "\n",
        "Analysing the Dataset by using Exploratory Data Analysis.\n",
        "Using Exponential Moving Averages analyse Trends and Seasonality in Roseman dataset.\n",
        "Analyse Regression analysis using following prediction analysis, A. Linear Regression Analysis B. Elastic Regression ( Lasso and Ridge Regression). C. Random Forest Regression. "
      ],
      "metadata": {
        "id": "jO1W0-O4Nc9B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pylab\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "store_df=pd.read_csv( 'store.csv')\n",
        "rossmann_df=pd.read_csv( 'Copy of Rossmann Stores Data.zip')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "store_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_df.head()"
      ],
      "metadata": {
        "id": "JZbmJsSKTM3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rossmann_df.shape,store_df.shape"
      ],
      "metadata": {
        "id": "k-LE1Ss2TTee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "rossmann_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()\n"
      ],
      "metadata": {
        "id": "lCTi7fc4VvQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I looked for null values in store data.there were a lot of null values in some columns.the had to be dealt with.So i wrote a code to specifically deal with the null values of each column either by replacing it with 0,mode or median.Removing the columns was not an option as they might remove some significant amount of data."
      ],
      "metadata": {
        "id": "4KGDqIMiWYRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.isnull().sum()"
      ],
      "metadata": {
        "id": "1dniZMojWnJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many Nan values in columns - '**CompetitionOpenSinceMonth**' , **'CompetitionOpenSinceYear, Promointerval', 'Promo2sinceWeek**' and **'Promo2sinceYear**'. Also **CompetitionDistance** has only 3 null values. we have to clean those data. "
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CompetitionDistance"
      ],
      "metadata": {
        "id": "nwwbmZnUXd2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_df[pd.isnull(store_df.CompetitionDistance)]"
      ],
      "metadata": {
        "id": "WfKmR75CXhqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we can fill these three values with many ways such as 0 or mean or mode or median. We decided to fill with it Median."
      ],
      "metadata": {
        "id": "LyViUUV8YKCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code for replacing Nan values in CompetitionDistance with median.\n",
        "store_df['CompetitionDistance'].fillna(store_df['CompetitionDistance'].median(), inplace = True)"
      ],
      "metadata": {
        "id": "FDIGDtgZYdiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear, Promointerval', 'Promo2sinceWeek' and 'Promo2sinceYear'**"
      ],
      "metadata": {
        "id": "nvxTUWdpYbZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are not much information provided to these data. Also we observe from dataset that where the Promo2 has value equals to zero there are Nan values for these columns. That means the store which do not wat promotion they have null values in promointerval , promo2sinceweek and so on.So for this purpose the best way to fill those features is to assign value equals to zero."
      ],
      "metadata": {
        "id": "RcPi-wgTZxX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code for replacing Nan values with 0.\n",
        "\n",
        "store_new = store_df.copy()\n",
        "\n",
        "## Replacing Nan values with 0 in CompetitionOpenSinceMonth\n",
        "store_new['CompetitionOpenSinceMonth'] = store_new['CompetitionOpenSinceMonth'].fillna(0)\n",
        "\n",
        "## Replacing Nan values with 0 in CompetitionOpenSinceYear\n",
        "store_new['CompetitionOpenSinceYear'] = store_new['CompetitionOpenSinceYear'].fillna(0)\n",
        "\n",
        "## Replacing Nan values with 0 in Promo2SinceWeek\n",
        "store_new['Promo2SinceWeek'] = store_new['Promo2SinceWeek'].fillna(0)\n",
        "\n",
        "## Replacing Nan values with 0 in Promo2SinceYear\n",
        "store_new['Promo2SinceYear'] = store_new['Promo2SinceYear'].fillna(0)\n",
        "\n",
        "## Replacing Nan values with 0 in PromoInterval\n",
        "store_new['PromoInterval'] = store_new['PromoInterval'].fillna(0)\n",
        "\n",
        "## Now checking Nan values\n",
        "store_new.isna().sum()"
      ],
      "metadata": {
        "id": "vzNRo0OZaIw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge the Rossmann_df and Store_df csv by column 'Store' as in both csv Store column is common.**"
      ],
      "metadata": {
        "id": "SYLetwRbap6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1 = pd.merge(rossmann_df, store_new, on='Store', how='left')\n",
        "final1.head()"
      ],
      "metadata": {
        "id": "d9B0llLqax-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.shape"
      ],
      "metadata": {
        "id": "yP-FjZ5abye2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changing different dtypes to int type.**"
      ],
      "metadata": {
        "id": "_Cu-KWMFcB-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing StateHoliday dtype from object to int.\n",
        "final1.loc[final1['StateHoliday'] == '0', 'StateHoliday'] = 0\n",
        "final1.loc[final1['StateHoliday'] == 'a', 'StateHoliday'] = 1\n",
        "final1.loc[final1['StateHoliday'] == 'b', 'StateHoliday'] = 2\n",
        "final1.loc[final1['StateHoliday'] == 'c', 'StateHoliday'] = 3\n",
        "final1['StateHoliday'] = final1['StateHoliday'].astype(int, copy=False)\n",
        "\n",
        "print('levels :', final1['StateHoliday'].unique(), '; data type :', final1['StateHoliday'].dtype)"
      ],
      "metadata": {
        "id": "0RYHmXImcpbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# code for changing Assortment dtype from object to int.\n",
        "final1.loc[final1['Assortment'] == 'a', 'Assortment'] = 0\n",
        "final1.loc[final1['Assortment'] == 'b', 'Assortment'] = 1\n",
        "final1.loc[final1['Assortment'] == 'c', 'Assortment'] = 2\n",
        "final1['Assortment'] = final1['Assortment'].astype(int, copy=False)\n",
        "\n",
        "print('levels :', final1['Assortment'].unique(), '; data type :', final1['Assortment'].dtype)"
      ],
      "metadata": {
        "id": "ypf53gmqcwsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing StoreType dtype from object to int.\n",
        "final1.loc[final1['StoreType'] == 'a', 'StoreType'] = 0\n",
        "final1.loc[final1['StoreType'] == 'b', 'StoreType'] = 1\n",
        "final1.loc[final1['StoreType'] == 'c', 'StoreType'] = 2\n",
        "final1.loc[final1['StoreType'] == 'd', 'StoreType'] = 3\n",
        "final1['StoreType'] = final1['StoreType'].astype(int, copy=False)\n",
        "\n",
        "print('levels :', final1['StoreType'].unique(), '; data type :', final1['StoreType'].dtype)"
      ],
      "metadata": {
        "id": "g9YU0cdFc47_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for changing format of date from object to datetime\n",
        "final1['Date'] = pd.to_datetime(final1['Date'], format= '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "dRw_aKuidDtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1['CompetitionOpenSinceYear']= final1['CompetitionOpenSinceYear'].astype(int)\n",
        "final1['Promo2SinceYear']= final1['Promo2SinceYear'].astype(int)"
      ],
      "metadata": {
        "id": "qTHbVfMcdNV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1['CompetitionOpenSinceMonth'] = pd.DatetimeIndex(final1['Date']).month"
      ],
      "metadata": {
        "id": "RQ8l6zildWp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1['CompetitionDistance']= final1['CompetitionDistance'].astype(int)\n",
        "final1['Promo2SinceWeek']= final1['Promo2SinceWeek'].astype(int)"
      ],
      "metadata": {
        "id": "wtAMOssUdbWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**checking dtypes of columns**"
      ],
      "metadata": {
        "id": "gVSVGzfFdhl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1.dtypes"
      ],
      "metadata": {
        "id": "J4AfxmrSdm-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "lELKMyeZiHZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1.head()"
      ],
      "metadata": {
        "id": "w-5vRA2HiNr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.describe().apply(lambda s: s.apply('{0:.2f}'.format))"
      ],
      "metadata": {
        "id": "-G-X-d0wiVQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.tail()"
      ],
      "metadata": {
        "id": "EC5e6t5miaV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.info"
      ],
      "metadata": {
        "id": "Wkv70iYAifBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sales**"
      ],
      "metadata": {
        "id": "6qQ58VoqijQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'CompetitionOpenSinceYear', y= 'Sales', data=final1)\n",
        "plt.title('Plot between Sales and Competition Open Since year')"
      ],
      "metadata": {
        "id": "GIhZul3Tir6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the Plot we can tell that Sales are high during the year 1900, as there are very few store were operated of Rossmann so there is less competition and sales are high. But as year pass on number of stores increased that means competition also increased and this leads to decline in the sales."
      ],
      "metadata": {
        "id": "-_gh6nnQjv-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'Promo2SinceYear', y= 'Sales', data=final1)\n",
        "plt.title('Plot between Sales and Promo2 Since year')"
      ],
      "metadata": {
        "id": "jsg5u4p8j7mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Sales and promo2 since year shows that effect of sales of stores which continue their promotion. this data is available from yaer 2009 to 2015. Promo2 has very good effect on sales but in year 2013 sales be minimum and also in year 2012 and 2015 sales are very low."
      ],
      "metadata": {
        "id": "oL9h0uhukCEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'CompetitionOpenSinceMonth', y= 'Sales', data=final1)\n",
        "plt.title('Plot between Sales and Competition Open Since Month')"
      ],
      "metadata": {
        "id": "TMHMtkC80yA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Competition open since month and Sales explains the sales data in each month of a year. This data shows that sales after month november increases drastically. This is very clear that in December monthdue to Christmas Eve and New year celebration everone is buying. So sales of Rossmann store is very high in December."
      ],
      "metadata": {
        "id": "4LUNHRz_1DdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.pointplot(x= 'DayOfWeek', y= 'Sales', data=final1)\n",
        "plt.title('Plot between Sales and Day of Week')"
      ],
      "metadata": {
        "id": "cMRrNWjG1TNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot between Sales and Days of week shows that maximum sales is on Monday and sales gradually decreasing to 6th day of week i.e. on Saturday. It also shows that sales on Sunday is almost near to zero as on sunday maximum stores are closed."
      ],
      "metadata": {
        "id": "uUAJtYFB1iQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**BoxPlot of sales between Assortment and store type** "
      ],
      "metadata": {
        "id": "RtJXBFwj1nR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sns.catplot(data= final1, x= 'CompetitionOpenSinceMonth', y= 'Customers', col='StoreType', palette='plasma',\n",
        "  #                             hue= 'StoreType', row='Promo', color= 'c')"
      ],
      "metadata": {
        "id": "0f3R6D_g2WPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plot_storetype_sales = sns.boxplot(x=\"StoreType\", y=\"Sales\", data=final1)\n",
        "plt.title('Boxplot For Sales Values')"
      ],
      "metadata": {
        "id": "eMEKg0xb2fKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plot_storetype_sales = sns.boxplot(x=\"Assortment\", y=\"Sales\", data=final1)\n",
        "plt.title('Boxplot For Sales Values on the basis of Assortment Level')"
      ],
      "metadata": {
        "id": "lnPx6JDu3wqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x= 'DayOfWeek', hue='Open', data= final1, palette='cool')\n",
        "plt.title('Store Daily Open Countplot')"
      ],
      "metadata": {
        "id": "1bbCl2Gy357J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x= 'DayOfWeek', hue='Promo', data= final1, palette='cool')\n",
        "plt.title('Store Daily Promo Countplot')"
      ],
      "metadata": {
        "id": "45IGduhv4Esd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Promo**"
      ],
      "metadata": {
        "id": "5LWtc2ul4I5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "promo_sales = sns.barplot(x=\"Promo\", y=\"Sales\", data=final1, palette='RdPu')"
      ],
      "metadata": {
        "id": "WlZ7_0h34OaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplot between promo and Sales shows the effect of promotion on Sales. Here 0 represents the store which didnt opt for promotion and 1 represents for stores who opt for promotion. Those store who took promotions their sales are high as compared to stores who didnt took promotion."
      ],
      "metadata": {
        "id": "7u_hpOIl4bG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StateHoliday and SchoolHoliday**"
      ],
      "metadata": {
        "id": "ofVqsAUZ4jWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales during State Holiday"
      ],
      "metadata": {
        "id": "5tnB_6EH4moy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 = public holiday, 1 = Easter holiday, 2 = Christmas, 3 = None"
      ],
      "metadata": {
        "id": "JGAcjZ5d4pKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stateholiday_sales = sns.barplot(x=\"StateHoliday\", y=\"Sales\", data=final1)"
      ],
      "metadata": {
        "id": "b-BSOTTw4tBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales during school holiday"
      ],
      "metadata": {
        "id": "UnjV4Nga49yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schoolholiday_sales = sns.barplot(x=\"SchoolHoliday\", y=\"Sales\", data=final1)"
      ],
      "metadata": {
        "id": "88oMwL__4-9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that most of the stores remain closed during State and Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays. Another important thing to note is that the stores which were opened during School holidays had more sales than normal."
      ],
      "metadata": {
        "id": "syq4sp9B5Osz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Store Type**"
      ],
      "metadata": {
        "id": "vWTbh8Cd6Frt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(rossmann_df, store_new, on='Store', how='left')"
      ],
      "metadata": {
        "id": "bWb277V-6WRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "fig, axes = plt.subplots(2, 2,figsize=(17,10) )\n",
        "palette = itertools.cycle(sns.color_palette(n_colors=4))\n",
        "plt.subplots_adjust(hspace = 0.28)\n",
        "axes[0,0].bar(merged_df.groupby(by=\"StoreType\").count().Store.index ,merged_df.groupby(by=\"StoreType\").count().Store,color=[next(palette),next(palette),next(palette),next(palette)])\n",
        "axes[0,0].set_title(\"Number of Stores per Store Type \\n Fig 1.1\")\n",
        "axes[0,1].bar(merged_df.groupby(by=\"StoreType\").sum().Store.index,merged_df.groupby(by=\"StoreType\").sum().Sales/1e9,color=[next(palette),next(palette),next(palette),next(palette)])\n",
        "axes[0,1].set_title(\"Total Sales per Store Type \\n Fig 1.2\")\n",
        "axes[1,0].bar(merged_df.groupby(by=\"StoreType\").sum().Customers.index,merged_df.groupby(by=\"StoreType\").sum().Customers/1e6,color=[next(palette),next(palette),next(palette),next(palette)])\n",
        "axes[1,0].set_title(\"Total Number of Customers per Store Type (in Millions) \\n Fig 1.3\")\n",
        "axes[1,1].bar(merged_df.groupby(by=\"StoreType\").sum().Customers.index,merged_df.groupby(by=\"StoreType\").Sales.mean(),color=[next(palette),next(palette),next(palette),next(palette)])\n",
        "axes[1,1].set_title(\"Average Sales per Store Type \\n Fig 1.4\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L9enwXpB68YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this training set we can see that Storetype A has the highest number of branches,sales and customers from the 4 different storetypes. But this doesn't mean it's the best performing Storetype.\n",
        "\n",
        "When looking at the average sales and number of customers, we see that actually it is Storetype B who was the highest average Sales and highest average Number of Customers.\n",
        "\n",
        "**Assortments**\n",
        "\n",
        "As we cited in the description, assortments have three types and each store has a defined type and assortment type:\n",
        "\n",
        "a means basic things\n",
        "b means extra things\n",
        "c means extended things so the highest variety of products."
      ],
      "metadata": {
        "id": "mWE5S6AH7C3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Storetype_Assortment = sns.countplot(x=\"StoreType\",hue=\"Assortment\",order=[\"a\",\"b\",\"c\",\"d\"], data=merged_df,palette=sns.color_palette(n_colors=3)).set_title(\"Number of Different Assortments per Store Type\")\n",
        "merged_df.groupby(by=[\"StoreType\",\"Assortment\"]).Assortment.count()"
      ],
      "metadata": {
        "id": "CeG7z_bq7M9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see here that most of the stores have either a assortment type or c assortment type. Interestingly enough StoreType d which has the highest Sales per customer average actually has mostly c assortment type, this is most probably the reason for having this high average in Sales per customer.Having variety in stores always increases the customers spending pattern."
      ],
      "metadata": {
        "id": "KejI6wrw7aW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. There are two datasets - 1) **Rossmann.csv** & 2) **Store.csv**\n",
        "2. Shape of Rossmann dataset = (1017209,8) shape of store dataset = (1115, 10)\n",
        "3. In both dataset 'Store' column is common. So we do inner join on the basis of column 'Store'.\n",
        "4. On looking on datasets we find lots of Nan values in Store dataset.\n",
        "5. Try to replace Nan values with suitable values. In **CompetitionDistance** column only 3 Nan values are there. So we replaced it with **median**.\n",
        "6. Now for rest columns(**CompetitionOpenSinceMonth**, **CompetitionOpenSinceYear**, **Promo2**, **romointerval**) there are lots of Nan values and best way to treat this values to replace with 0.\n",
        "7. After combining shape of final dataset = (1017209,18)\n",
        "Also there is some columns such as '**StateHoliday**', '**SchoolHoliday**' & '**Assortment**' which contains object values. So, try to change into int by giving suitable values.\n",
        "\n",
        "I also did some graphs analysis and conclusions we got are:-\n",
        "\n",
        "1. From plot sales and competition Open Since Month shows sales go increasing from Novemmber and highest in month December. This may be due to Christmas eve and New Year.\n",
        "2. From plot Sales and day of week, Sales highest on Monday and start declinig from tuesday to saturday and on Sunday Sales almost near to Zero. This is because on Sunday all stores be closed.\n",
        "3. Plot between promotion and Sales shows that promotion helps in increasing Sales. This similar trends also shows with customers.\n",
        "4. Plot between StateHolidays and sales shows that during Public holiday sales are actually high but for other holidays such as Easter and Christmas sales be very low. This is because During Easter and Christmas stores also closed so sales goes down.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S4U-Hxnu8QDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**\n",
        "\n",
        "**Correlation**"
      ],
      "metadata": {
        "id": "okMUuLWueMHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['DayOfWeek', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'Promo2SinceWeek',\n",
        "                    'CompetitionDistance','CompetitionOpenSinceMonth','CompetitionOpenSinceYear',\n",
        "                    'Promo2','Promo2SinceWeek','Promo2SinceYear']"
      ],
      "metadata": {
        "id": "THEUFwOTedZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numeric_features[0:-1]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = final1[col]\n",
        "    label = final1['Sales']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Sales')\n",
        "    ax.set_title('Sales vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(final1[col], final1['Sales'], 1)\n",
        "    y_hat = np.poly1d(z)(final1[col])\n",
        "\n",
        "    plt.plot(final1[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XiRwxCObeiy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation\n",
        "plt.figure(figsize=(18,8))\n",
        "correlation = final1.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "D4koaZ7UgCKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multicollinearity**"
      ],
      "metadata": {
        "id": "27KRFTBCbUDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "yQmX8WkjbjAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(final1[[i for i in final1.describe().columns if i not in ['Sales']]])"
      ],
      "metadata": {
        "id": "VAP5mrEDbu0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicolinearity of columns like 'Promo2SinceYear' is pretty high so we decided to drop it"
      ],
      "metadata": {
        "id": "WoO5qmWFhLoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(final1[[i for i in final1.describe().columns if i not in ['Sales','Promo2SinceYear']]])"
      ],
      "metadata": {
        "id": "qQgIEaeNhNbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for each feature VIF values below 10. That's look pretty fine."
      ],
      "metadata": {
        "id": "jnZejbkGhiEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis on Sales - Dependent variable**"
      ],
      "metadata": {
        "id": "ekz_6QdLh1GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(final1['Sales']).hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DRxrfVqDh5du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now checking for number of sales =0."
      ],
      "metadata": {
        "id": "4TGoQRjWh_KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1[(final1.Open == 0) & (final1.Sales == 0)].count()[0]"
      ],
      "metadata": {
        "id": "js2E-iiYiCgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that 172817 times store is were temporarily closed for refurbishment. The best solution here is to get rid of closed stores and prevent the models to train on them and get false guidance"
      ],
      "metadata": {
        "id": "W74eImeEiLPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = final1.drop(final1[(final1.Open == 0) & (final1.Sales == 0)].index)"
      ],
      "metadata": {
        "id": "0_YFCPO7iI6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "h-Moflb4iRie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.shape"
      ],
      "metadata": {
        "id": "ydZF9kiOijmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PromoInterval to be changed into dummies as it is categorical feature."
      ],
      "metadata": {
        "id": "0m2hlP0fipDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.get_dummies(new_df, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "Dp9VJzF_ioDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "Oz2yCN62kO2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL TRAINING**"
      ],
      "metadata": {
        "id": "gn_C3HF2kSNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "rOqf5NzkkiCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 1 (excluding rows which has sales =0)**"
      ],
      "metadata": {
        "id": "dgN5icpZkltu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was confused about whether to include rows where sales value is 0.So first we built a model excluding sales value and then including those values"
      ],
      "metadata": {
        "id": "L4hfqfmxkwkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dependent_variables = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "independent_variables = list(new_df.columns.drop(['Promo2SinceYear','Date','Sales']))"
      ],
      "metadata": {
        "id": "VakbEXn8k1r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "independent_variables"
      ],
      "metadata": {
        "id": "6dltKbemk7o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "X = new_df[independent_variables].values\n",
        "\n",
        "# Create the data of dependent variable\n",
        "y = new_df[dependent_variables].values"
      ],
      "metadata": {
        "id": "vhAiG7wMlCPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "hTyykRZllOBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "GHbzAQ_mlRDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ewUjMiSklVA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "qzD4u1FhlYmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.coef_"
      ],
      "metadata": {
        "id": "9WFAvuDblbsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.intercept_"
      ],
      "metadata": {
        "id": "19_oVJIYlep4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "H4xzI9TIlhje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = reg.predict(X_train)\n",
        "y_pred_train"
      ],
      "metadata": {
        "id": "uySeOpCDlmW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "um7JaT6dlqLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "uF61loz5ltjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE  = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)"
      ],
      "metadata": {
        "id": "xGOZsEpHl4Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "JWUNHI0ZmACV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LASSO**"
      ],
      "metadata": {
        "id": "TO2MGqstmDCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L1 = Lasso(alpha = 0.2, max_iter=10000)"
      ],
      "metadata": {
        "id": "CSARUTGXmHGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7dtFoVXQmKRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = L1.predict(X_test)"
      ],
      "metadata": {
        "id": "6E_gZw3rmO4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "OQe1e66lmVJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(y_test, y_pred_lasso), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "W0Wngs79mYdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RIDGE**"
      ],
      "metadata": {
        "id": "83rwSoZZmeHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2 = Ridge(alpha = 0.5)"
      ],
      "metadata": {
        "id": "9fCsz233mheK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "V91TA17OmkOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.predict(X_test)"
      ],
      "metadata": {
        "id": "Y4qllhLimnQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "2XrraaE-mnzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREE**"
      ],
      "metadata": {
        "id": "Jw-wxUDpmton"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "y_train_dt = decision_tree.predict(X_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(y_test, y_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "H6SNZIZZqOO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 2 (By taking whole Dataset)**"
      ],
      "metadata": {
        "id": "lepDFUdQ8BYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use dummy variables for the column 'PromoInterval'"
      ],
      "metadata": {
        "id": "_psMV2T48LXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final1 = pd.get_dummies(final1, columns=['PromoInterval'])"
      ],
      "metadata": {
        "id": "SICO6zGv8N3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.head()"
      ],
      "metadata": {
        "id": "pfgouk4_8TBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1.shape"
      ],
      "metadata": {
        "id": "9OiDKFJl8nbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define dependent and independent variables and convert them into arrays"
      ],
      "metadata": {
        "id": "J6Rvioeu8qjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining dependent variable\n",
        "dep_var = 'Sales'\n",
        "\n",
        "# defining independent variable\n",
        "indep_var = final1.columns.drop(['Store', 'Promo2SinceYear','Date','Sales'])"
      ],
      "metadata": {
        "id": "VCkdRIes8tLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the data of independent variables\n",
        "U = final1[indep_var].values\n",
        "\n",
        "# Create the dependent variable data\n",
        "v = final1[dep_var].values"
      ],
      "metadata": {
        "id": "mkcETfjO8240"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final1[indep_var]"
      ],
      "metadata": {
        "id": "IT_BNXvN9Ahy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I have done a train test split keeping the test size as 0.25**"
      ],
      "metadata": {
        "id": "pjNAZsZX9QT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset\n",
        "U_train, U_test, v_train, v_test = train_test_split(U, v, test_size=0.25, random_state = 0)\n",
        "print(U_train.shape)\n",
        "print(U_test.shape)"
      ],
      "metadata": {
        "id": "GpN6x43Q9aKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "EGbVylTv9d3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scling the x values\n",
        "scaler=StandardScaler()\n",
        "\n",
        "U_train = scaler.fit_transform(U_train)\n",
        "U_test = scaler.transform(U_test)"
      ],
      "metadata": {
        "id": "WzBzTdx69lCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the data into Lineat Regression Model\n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.fit(U_train, v_train)"
      ],
      "metadata": {
        "id": "RKF17buq9p3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred=linear_regression.predict(U_test)\n",
        "v_pred"
      ],
      "metadata": {
        "id": "CJl2hnT6-V-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression.score(U_train, v_train)"
      ],
      "metadata": {
        "id": "3ka-5Y07-ePq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regression_Dataframe = pd.DataFrame(zip(v_test, v_pred), columns = ['actual', 'pred'])\n",
        "regression_Dataframe"
      ],
      "metadata": {
        "id": "W59_NlOX-jzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_mean=final1[dep_var].mean()"
      ],
      "metadata": {
        "id": "VmIer4DO-n8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE  = mean_squared_error(v_test, v_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "tErb_lW2-rcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREE**"
      ],
      "metadata": {
        "id": "AvYOIOmK--KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree=DecisionTreeRegressor(max_depth=5)\n",
        "decision_tree.fit(U_train, v_train)\n",
        "v_pred_dt = decision_tree.predict(U_test)\n",
        "v_train_dt = decision_tree.predict(U_train)\n",
        "#print('dt_regressor R^2: ', r2(v_test,v_pred))\n",
        "MSE  = mean_squared_error(v_test, v_pred_dt)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_dt)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "upC_iPBW_BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decisiontree_Dataframe = pd.DataFrame(zip(v_test, v_pred_dt), columns = ['actual', 'pred'])\n",
        "decisiontree_Dataframe"
      ],
      "metadata": {
        "id": "42S35Onq_Ehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FOREST**"
      ],
      "metadata": {
        "id": "lEWCZkjU_Iew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest=RandomForestRegressor(n_estimators =500,max_depth=8)\n",
        "random_forest.fit(U_train, v_train)\n",
        "v_pred_rf=random_forest.predict(U_test)\n",
        "MSE  = mean_squared_error(v_test, v_pred_rf)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_rf)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "G7w0vIDa_MoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_Dataframe = pd.DataFrame(zip(v_test, v_pred_rf), columns = ['actual', 'pred'])\n",
        "rf_Dataframe"
      ],
      "metadata": {
        "id": "p3-IPUFZYo2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nTJm93C2ebcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso**"
      ],
      "metadata": {
        "id": "4CL3je2mYu65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha = 2.0)"
      ],
      "metadata": {
        "id": "O5y-X48wY-qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.fit(U_train, v_train)"
      ],
      "metadata": {
        "id": "HxTwNa0lZDM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_lasso = lasso.predict(U_test)"
      ],
      "metadata": {
        "id": "Jf9wgNhPZGqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(U_train, v_train)"
      ],
      "metadata": {
        "id": "RFUypbw4ZJl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(zip(v_test, v_pred_lasso), columns = ['actual', 'pred'])"
      ],
      "metadata": {
        "id": "FhpwwiM4ZOH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ridge**"
      ],
      "metadata": {
        "id": "gM3NcdSOZRLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha = 0.5)"
      ],
      "metadata": {
        "id": "XYpAwR09ZgwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(U_train, v_train)"
      ],
      "metadata": {
        "id": "ZltTznOVZlkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_pred_rid=ridge.predict(U_test)"
      ],
      "metadata": {
        "id": "yG1BsTymZoIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(U_test, v_test)"
      ],
      "metadata": {
        "id": "1k-fDhn2Zq14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(v_test, v_pred_rid)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_rid)\n",
        "print(\"R2 :\" ,r2)"
      ],
      "metadata": {
        "id": "VaPvLouyZ8zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Light GBM Model :**"
      ],
      "metadata": {
        "id": "__07z0dkaGwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model=lgb.LGBMRegressor(n_estimators=700)\n",
        "#model.fit(U_train,v_train)\n",
        "#v_pred_lgb=model.predict(U_test)"
      ],
      "metadata": {
        "id": "pgnHo5dPaKV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"MSE  = mean_squared_error(v_test, v_pred_lgb)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "RMPSE=RMSE/sales_mean\n",
        "print(\"RMPSE :\",RMPSE)\n",
        "\n",
        "r2 = r2_score(v_test, v_pred_lgb)\n",
        "print(\"R2 :\" ,r2)\"\"\""
      ],
      "metadata": {
        "id": "sNqJZklwaMzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided not to include the LightGBM model as I had a strong intuition that it is overfitting as it is giving abnormally high accuracy.But this can be included in future developement of this project"
      ],
      "metadata": {
        "id": "HZi3ChMwacZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion from Model Training**\n",
        "\n",
        "I saw that Sales column contains 172817 rows with 0 sale. So we created a new dataframe in which we removed 0 sales rows and tried to train our model. We used various algorithms and got accuracy score around 74%.\n",
        "\n",
        "We werealso curious about the total dataset(including Sales = 0 rows). So we trained another model using various algorithms and we got accuracy near about 92% which is far better than previous model.\n",
        "\n",
        "So we came to conclusion that removing sales=0 rows actually removes lot of information from dataset as it has 172817 rows which is quite large and therefore we decided not to remove those values.We got our best rmpse score from Random Forest model,we tried taking an optimum parameter so that our model doesnt overfit."
      ],
      "metadata": {
        "id": "kCwXVECPajrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSION FROM EDA**\n",
        "\n",
        "1)From plot sales and competition Open Since Month shows sales go increasing from November and highest in month December.\n",
        "\n",
        "2)From plot Sales and day of week, Sales highest on Monday and start declining from Tuesday to Saturday and on Sunday Sales almost near to Zero.\n",
        "\n",
        "3)Plot between Promotion and Sales shows that promotion helps in increasing Sales.\n",
        "\n",
        "4)Type of Store plays an important role in opening pattern of stores.\n",
        "\n",
        "5)All Type ‘b’ stores never closed except for refurbishment or other reason.\n",
        "\n",
        "6)All Type ‘b’ stores have comparatively higher sales and it mostly constant with peaks appears on weekends.\n",
        "\n",
        "7)ssortment Level ‘b’ is only offered at Store Type ‘b’.\n",
        "\n",
        "8)We can observe that most of the stores remain closed during State Holidays. But it is interesting to note that the number of stores opened during School Holidays were more than that were opened during State Holidays."
      ],
      "metadata": {
        "id": "pul7vHtqa7s4"
      }
    }
  ]
}